{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        Initiate nn.Linear modules\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.input_hidden = torch.nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.input_output = torch.nn.Linear(input_size + hidden_size, output_size)\n",
    "        \n",
    "        self.softmax = torch.nn.LogSoftmax()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Get your Varible and return prediction\n",
    "        \"\"\"\n",
    "        inandhidden = torch.cat((x, hidden), 1)\n",
    "        hidden = self.input_hidden(inandhidden)\n",
    "        output = self.input_output(inandhidden)\n",
    "        prediction = self.softmax(output)\n",
    "        \n",
    "        return prediction, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_letters = 57\n",
    "n_hidden = 128\n",
    "n_categories = 18\n",
    "batch_size, input_size, hidden_size, output_size = 1, n_letters, n_hidden, n_categories\n",
    "learning_rate = 5e-3  # 1e-6 is too small here with nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.randn(batch_size, input_size), requires_grad = False) # False is default\n",
    "y = Variable(torch.randn(batch_size, output_size), requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.nn.Sequential(\n",
    "#         torch.nn.Linear(input_size, hidden_size),\n",
    "#         torch.nn.ReLU(),\n",
    "#         torch.nn.Linear(hidden_size, output_size))\n",
    "model  = RNN(input_size, hidden_size, output_size)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hansol/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "all_losses = []\n",
    "\n",
    "for i in range(500):\n",
    "    # initialize hidden\n",
    "    hidden = model.init_hidden()\n",
    "    \n",
    "    # forward\n",
    "    prediction, hidden = model(x, hidden)\n",
    "\n",
    "    # loss\n",
    "    loss = loss_fn(prediction, y)\n",
    "    all_losses.append(loss)\n",
    "#     print('i = %d, loss = %d' %(i, loss.data))\n",
    "    \n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcd3f369cc0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(10.0903, grad_fn=<MseLossBackward>),\n",
       " tensor(9.9359, grad_fn=<MseLossBackward>),\n",
       " tensor(9.8305, grad_fn=<MseLossBackward>),\n",
       " tensor(9.7579, grad_fn=<MseLossBackward>),\n",
       " tensor(9.7074, grad_fn=<MseLossBackward>),\n",
       " tensor(9.6722, grad_fn=<MseLossBackward>),\n",
       " tensor(9.6476, grad_fn=<MseLossBackward>),\n",
       " tensor(9.6303, grad_fn=<MseLossBackward>),\n",
       " tensor(9.6181, grad_fn=<MseLossBackward>),\n",
       " tensor(9.6096, grad_fn=<MseLossBackward>),\n",
       " tensor(9.6035, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5992, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5961, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5939, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5924, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5912, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5904, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5899, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5894, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5891, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5889, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5887, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5886, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5885, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5885, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5884, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5884, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5884, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5884, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>),\n",
       " tensor(9.5883, grad_fn=<MseLossBackward>)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "something is going!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
